{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 8: Model Development\n",
    "\n",
    "## Objectives\n",
    "\n",
    "After this tutorial you will be able to:\n",
    "\n",
    "*   Use `scikit-learn` to perform simple linear regression to predict outputs\n",
    "*   Use `scikit-learn` to perform multiple linear regression to predict outputs\n",
    "*   Use `scikit-learn` to perform non-linear regression to predict outputs\n",
    "*   Evaluate the developed models and select the appropriate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        <a href=\"#import\">Import dataset</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#reg\">Regression Overview</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#slr\">Simple Linear Regression</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#mlr\">Multiple Linear Regression</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#nlr\">Non-Linear Regression</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#pipe\">Pipelines and Grid Search</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#eval\">Visual Evaluation of Higher Dimensional Models</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#class\">Classification</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#log\">Logistic Regression</a>\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr id=\"import\">\n",
    "\n",
    "<h2>1. Import the dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from `csv` into a `Pandas DataFrame`\n",
    "\n",
    "### Understanding the Data\n",
    "\n",
    "This dataset contains information about vehicle specifications, fuel consumption, and CO₂ emissions. Each row represents a unique vehicle model with various attributes related to its design, fuel efficiency, and environmental impact.\n",
    "\n",
    "#### Column Descriptions\n",
    "\n",
    "- **Make**: The brand or manufacturer of the vehicle (e.g., ACURA, BMW).\n",
    "- **Model**: The specific model of the vehicle, with additional descriptors:\n",
    "  - **4WD/4X4**: Four-wheel drive\n",
    "  - **AWD**: All-wheel drive\n",
    "  - **FFV**: Flexible-fuel vehicle\n",
    "  - **SWB**: Short wheelbase\n",
    "  - **LWB**: Long wheelbase\n",
    "  - **EWB**: Extended wheelbase\n",
    "\n",
    "- **Vehicle Class**: The category of the vehicle based on size and design (e.g., Compact, SUV - Small).\n",
    "- **Engine Size [L]**: The engine size in liters, indicating the displacement capacity of the engine.\n",
    "- **Cylinders**: The number of cylinders in the engine, impacting performance and fuel efficiency.\n",
    "- **Transmission**: The type of transmission and its characteristics:\n",
    "  - **A**: Automatic\n",
    "  - **AM**: Automated manual\n",
    "  - **AS**: Automatic with select shift\n",
    "  - **AV**: Continuously variable\n",
    "  - **M**: Manual\n",
    "  - **3-10**: Number of gears in the transmission\n",
    "\n",
    "- **Fuel Type**: The type of fuel the vehicle uses:\n",
    "  - **X**: Regular gasoline\n",
    "  - **Z**: Premium gasoline\n",
    "  - **D**: Diesel\n",
    "  - **E**: Ethanol (E85)\n",
    "  - **N**: Natural gas\n",
    "\n",
    "- **Fuel Consumption**:\n",
    "  - **Fuel Consumption City [L/100 km]**: Fuel consumption rating for city driving in liters per 100 kilometers.\n",
    "  - **Fuel Consumption Hwy [L/100 km]**: Fuel consumption rating for highway driving in liters per 100 kilometers.\n",
    "  - **Fuel Consumption Comb [L/100 km]**: Combined fuel consumption rating (55% city, 45% highway) in liters per 100 kilometers.\n",
    "  - **Fuel Consumption Comb [mpg]**: Combined fuel consumption rating in miles per imperial gallon (mpg).\n",
    "\n",
    "- **CO₂ Emissions [g/km]**: Tailpipe emissions of carbon dioxide in grams per kilometer for combined city and highway driving.\n",
    "\n",
    "#### Dataset Purpose and Use\n",
    "This dataset provides insights into vehicle fuel efficiency and emissions, which can be used for:\n",
    "- **Comparing vehicle fuel efficiency** across different makes and models.\n",
    "- **Evaluating CO₂ emissions** based on fuel type and vehicle class.\n",
    "- **Analyzing fuel consumption patterns** for city, highway, and combined driving conditions.\n",
    "- **Supporting regulatory compliance** and environmental impact assessments by tracking emission levels.\n",
    "\n",
    "This dataset can be visualized to identify trends in fuel efficiency, highlight differences across vehicle classes, and understand how vehicle specifications impact emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CO2_Emissions_Canada.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information about the columns of the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fuel Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Fuel Type'] != 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr id=\"reg\">\n",
    "\n",
    "<h2>2. Regression Overview</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "Regression is a statistical technique used to model the relationship between one or more independent variables (also known as features or predictors) and a dependent variable (also known as the target or response variable).  \n",
    "The goal of regression is to understand how changes in the independent variables affect the dependent variable. Regression is a powerful tool for prediction, forecasting, and understanding complex relationships in data.  \n",
    "\n",
    "#### Goodness of fitting\n",
    "Fitting goodness is about finding the optimum spot between capturing the data's essence without getting \"too close\" or being \"too simple.\" It's a balancing act between complexity and generalizability, ensuring the model performs well not just on the data it saw, but on the real world it faces.\n",
    "\n",
    "**Underfitting:**  \n",
    "The model is too simple and captures only the basic trends, underestimating the true complexity of the data. This leads to inaccurate predictions for both training and unseen data.\n",
    "\n",
    "**Good Fitting:**  \n",
    "The model captures the main trends and patterns in the data, leading to accurate predictions on unseen examples. It balances complexity and flexibility without overfitting.\n",
    "\n",
    "**Overfitting:**  \n",
    "The model memorizes the training data too closely, capturing even the noise and random fluctuations. This leads to excellent performance on the training data but poor generalizability to new examples.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"fitting.webp\">\n",
    "</div>\n",
    "\n",
    "#### Steps\n",
    "General steps to perform regression using `scikit-learn`:\n",
    "\n",
    "\n",
    "1. **Data Loading**: extract input features (x) and output target (y)\n",
    "\n",
    "2. **Data Preprocessing (if necessary)**: prepare input features for the selected regression model\n",
    "\n",
    "3. **Data Splitting**: split data into training data and testing data for model evaluation\n",
    "\n",
    "4. **Model Training**: train/fit the selected regression model on the *training* data\n",
    "\n",
    "5. **Predictions**: make prediction (y_hat) using the trained model\n",
    "\n",
    "6. **Evaluation**: evaluate the performance of the model using appropriate metrics (i.e. MSE, R-squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr id=\"slr\">\n",
    "\n",
    "<h2>3. Simple Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple linear regression is a statistical method that models the linear relationship between a single independent variable and a dependent variable.\n",
    "\n",
    "The model is on the form:\n",
    "$$\n",
    "y = ax + b\n",
    "$$\n",
    "\n",
    "Where, \n",
    "- `a` is the slope of the independent parameter\n",
    "- `b` is the intercept with the Y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# get the input and output variables\n",
    "x = df[['Engine Size [L]']]\n",
    "y = df['CO2 Emissions [g/km]']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print('Coefficients: ', lr.coef_)\n",
    "print('Intercept: ', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = lr.predict(x_train)\n",
    "y_pred_test = lr.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model fit\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(x, lr.predict(x), color='red')\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('Engine Size [L]')\n",
    "plt.ylabel('CO2 Emissions [g/km]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the effect of other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(x='Engine Size [L]', y='CO2 Emissions [g/km]', size='Fuel Consumption Comb [L/100 km]', hue='Fuel Type', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# get the input and output variables\n",
    "x = df[['Fuel Consumption Comb [L/100 km]']]\n",
    "y = df['CO2 Emissions [g/km]']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "lr.fit(x_train, y_train)\n",
    "print('Coefficients: ', lr.coef_)\n",
    "print('Intercept: ', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = lr.predict(x_train)\n",
    "y_pred_test = lr.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model fit\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x, lr.predict(x), color='red')\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('Fuel Consumption Comb [L/100 km]')\n",
    "plt.ylabel('CO2 Emissions [g/km]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the effect of other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(df, x='Fuel Consumption Comb [L/100 km]', y='CO2 Emissions [g/km]', hue='Fuel Type', size='Engine Size [L]')\n",
    "plt.title('CO2 Emissions vs Fuel Consumption')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr id=\"mlr\">\n",
    "\n",
    "<h2>4. Multiple Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regression is an extension of simple linear regression that allows for the inclusion of multiple independent variables. It assumes that the relationship between the dependent variable and the independent variables is linear and additive, meaning that the effect of each independent variable on the dependent variable is independent of the other independent variables.\n",
    "\n",
    "The model is on the form:\n",
    "$$\n",
    "y = a_0 +  a_1x_1 + a_2x_2 + ...\n",
    "$$\n",
    "\n",
    "Where,\n",
    "- `a_0` is the intercept with the Y axis\n",
    "- `a_1, a_2, ...` is the slope of each independent parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# get the input and output variables\n",
    "x = df[['Engine Size [L]', 'Fuel Consumption Comb [L/100 km]']]\n",
    "y = df['CO2 Emissions [g/km]']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "lr.fit(x_train, y_train)\n",
    "print('Coefficients: ', lr.coef_)\n",
    "print('Intercept: ', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = lr.predict(x_train)\n",
    "y_pred_test = lr.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plotly to create an interactive 3D plot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# plot scatter plot in 3D\n",
    "fig = px.scatter_3d(df, x='Engine Size [L]', y='Fuel Consumption Comb [L/100 km]', z='CO2 Emissions [g/km]', color='Fuel Type')\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "\n",
    "# add linear regression surface\n",
    "x_grid = np.arange(0.0, 10.0, 0.1)\n",
    "y_grid = np.arange(0.0, 30.0, 0.1)\n",
    "x_grid, y_grid = np.meshgrid(x_grid, y_grid)\n",
    "x_lr = np.stack((x_grid.flatten(), y_grid.flatten()), axis=1)\n",
    "z_grid = lr.predict(x_lr).reshape(x_grid.shape)\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_grid,\n",
    "    y=y_grid,\n",
    "    z=z_grid,\n",
    "    opacity=0.2,\n",
    "    showscale=False,    \n",
    "    surfacecolor=z_grid-z_grid,\n",
    "))\n",
    "\n",
    "# update figure size\n",
    "fig.update_layout(\n",
    "    height=700,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr id=\"nlr\">\n",
    "\n",
    "<h2>5. Non-Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linear regression is a statistical method that models the relationship between a single or multiple independent variables and a dependent variable when the relationship is not linear.  \n",
    "Non-linear regression techniques can capture more complex relationships between variables than linear regression methods.  \n",
    "Some common non-linear regression techniques include polynomial regression, support vector regression (SVR), decision tree regression, and neural networks.\n",
    "\n",
    "For different non-linear equations (e.g. polynomial, exponential, etc.). It is common to linearize the equation, then perform linear regression on the linearized equation using the `LinearRegression()` model.\n",
    "\n",
    "For example, for a polynomial of the second degree:\n",
    "$$\n",
    "y = a_0 + a_1x + a_2x^2\n",
    "$$\n",
    "This can be linearized as follows:\n",
    "$$\n",
    "y = a_0 + a_1x_1 + a_2x_2\n",
    "$$\n",
    "Where,\n",
    "$$ \n",
    "x_1 = x  \\\\\n",
    "x_2 = x^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# get the input and output variables\n",
    "x = df[['Engine Size [L]']]\n",
    "y = df['CO2 Emissions [g/km]']\n",
    "\n",
    "# create polynomial features\n",
    "# automatically creates new columns for x^2, x^3, x^4, ... calculated from the input variable x\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "x_poly = poly.fit_transform(x)\n",
    "print('Polynomial features: ', x_poly.shape)\n",
    "print()\n",
    "print(x[:5])\n",
    "print()\n",
    "print(x_poly[:5])\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_poly, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "lr.fit(x_train, y_train)\n",
    "print('Coefficients: ', lr.coef_)\n",
    "print('Intercept: ', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = lr.predict(x_train)\n",
    "y_pred_test = lr.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model fit\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_test[:, 0], y_test, color='blue')\n",
    "x_fit = np.arange(0.0, 10.0, 0.1).reshape(-1, 1)\n",
    "x_fit_poly = poly.fit_transform(x_fit)\n",
    "y_fit = lr.predict(x_fit_poly)\n",
    "plt.plot(x_fit, y_fit, color='red')\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('Engine Size [L]')\n",
    "plt.ylabel('CO2 Emissions [g/km]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Non-Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# get the input and output variables\n",
    "x = df[['Engine Size [L]', 'Fuel Consumption Comb [L/100 km]']]\n",
    "y = df['CO2 Emissions [g/km]']\n",
    "\n",
    "# create polynomial features\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "x_poly = poly.fit_transform(x)\n",
    "print('Polynomial features: ', x_poly.shape)\n",
    "print()\n",
    "print(x[:5])\n",
    "print()\n",
    "print(x_poly[:5])\n",
    "print()\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_poly, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "lr.fit(x_train, y_train)\n",
    "print('Coefficients: ', lr.coef_)\n",
    "print('Intercept: ', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = lr.predict(x_train)\n",
    "y_pred_test = lr.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plotly to create an interactive 3D plot\n",
    "\n",
    "# plot scatter plot in 3D\n",
    "fig = px.scatter_3d(df, x='Engine Size [L]', y='Fuel Consumption Comb [L/100 km]', z='CO2 Emissions [g/km]', color='Fuel Type')\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "\n",
    "# add linear regression surface\n",
    "x_grid = np.arange(0.0, 10.0, 0.1)\n",
    "y_grid = np.arange(0.0, 30.0, 0.1)\n",
    "x_grid, y_grid = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "# create polynomial features\n",
    "x_poly_grid = np.stack((x_grid.flatten(), y_grid.flatten()), axis=1)\n",
    "x_poly_grid = poly.fit_transform(x_poly_grid)\n",
    "z_grid = lr.predict(x_poly_grid).reshape(x_grid.shape)\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_grid,\n",
    "    y=y_grid,\n",
    "    z=z_grid,\n",
    "    opacity=0.2,\n",
    "    showscale=False,    \n",
    "    surfacecolor=z_grid-z_grid,\n",
    "))\n",
    "\n",
    "# update figure size\n",
    "fig.update_layout(\n",
    "    height=700,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr id=\"pipe\">\n",
    "\n",
    "<h2>6. Pipelines and Grid Search</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "Scikit-learn pipelines chain together multiple preprocessing, transformation, and modeling steps in a sequential workflow. This simplifies machine learning workflows and improves code organization and readability.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "- Improved code organization and readability: Easier to understand and maintain workflows.\n",
    "- Reduced boilerplate code: Single call to fit and predict the entire pipeline.\n",
    "- Automatic cross-validation: Simplifies hyperparameter tuning by applying cross-validation to the entire pipeline.\n",
    "- Streamlined workflow: Automates data processing and model training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input and output variables\n",
    "x = df[['Engine Size [L]', 'Fuel Consumption Comb [L/100 km]']]\n",
    "y = df['CO2 Emissions [g/km]']\n",
    "\n",
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "pipe.fit(x_train, y_train)\n",
    "print('Coefficients: ', pipe['lr'].coef_)\n",
    "print('Intercept: ', pipe['lr'].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = pipe.predict(x_train)\n",
    "y_pred_test = pipe.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Scikit-learn's GridSearchCV (Grid Search Cross-Validation) is a hyperparameter tuning method that systematically evaluates model performance across a predefined grid of parameter values. It automates the process of exploring different training configurations, ultimately identifying the combination that yields the best performance on unseen data.\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "1. Generate parameter combinations: GridSearchCV iterates through all possible combinations of the specified parameter values.\n",
    "2. Train and evaluate models: For each combination, a separate model is trained on a subset of the data (one fold) and evaluated on the remaining folds (unseen data).\n",
    "3. Performance scoring: A chosen metric (e.g., accuracy, F1-score) is used to quantify the model's performance on each fold.\n",
    "4. Aggregate results: Scores are averaged across folds for each parameter combination.\n",
    "5. Identify best model: The combination with the highest average score is identified as the optimal configuration.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "- Improved model performance: By exploring various configurations, GridSearchCV optimizes hyperparameters, potentially leading to significantly better model performance.\n",
    "- Reduced manual effort: Automates the hyperparameter tuning process, saving time and effort compared to manual exploration.\n",
    "- Data-driven insights: Provides data-driven insights into how different parameter values influence model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# get the input and output variables\n",
    "x = df[['Engine Size [L]', 'Fuel Consumption Comb [L/100 km]']]\n",
    "y = df['CO2 Emissions [g/km]']\n",
    "\n",
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "# create grid search\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2, 3],\n",
    "}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "# get the best parameters\n",
    "print('Best parameters: ', grid.best_params_)\n",
    "print('Best score: ', grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = grid.predict(x_train)\n",
    "y_pred_test = grid.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr id=\"eval\">\n",
    "\n",
    "<h2>7. Visual Evaluation of Higher Dimensional Models</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a model with more than 2 input parameters (total dimensions > 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode \"fuel type\"\n",
    "types = {\n",
    "    'E': 1,\n",
    "    'X': 2,\n",
    "    'Z': 2,\n",
    "    'D': 3,\n",
    "}\n",
    "df['Fuel Type'] = df['Fuel Type'].map(types)\n",
    "\n",
    "df['Fuel Type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input and output variables\n",
    "x = df[['Engine Size [L]', 'Fuel Consumption Comb [L/100 km]', 'Fuel Type']]\n",
    "y = df['CO2 Emissions [g/km]']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = LinearRegression()\n",
    "# model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# fit the model\n",
    "model.fit(x_train, y_train)\n",
    "print('Coefficients: ', lr.coef_)\n",
    "print('Intercept: ', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_test = model.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_train, y_pred_train)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_train, y_pred_train)))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred_test)))\n",
    "print('RMSE: {:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))))\n",
    "print('R2: {:.2f}'.format(r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Predicted vs Actual Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions vs. the actual values for training and testing sets\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, y_pred_train, label='Training')\n",
    "plt.scatter(y_test, y_pred_test, label='Testing')\n",
    "\n",
    "# plot 45 degree line\n",
    "plt.plot(y, y, color='red')\n",
    "\n",
    "plt.title('Predictions vs. Actual Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Residuals Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the residuals vs. the predictions for training and testing sets\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred_train, y_pred_train - y_train, label='Training')\n",
    "plt.scatter(y_pred_test, y_pred_test - y_test, label='Testing')\n",
    "\n",
    "# plot 0 line\n",
    "plt.axhline(y=0, color='red')\n",
    "\n",
    "plt.title('Residuals vs. Predictions')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Feature Importances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot relative feature importance\n",
    "features = pd.Series(model.feature_importances_, index=x.columns)\n",
    "features.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=features, y=features.index)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export decision tree to a file to use later without retraining\n",
    "import joblib\n",
    "\n",
    "# save the model to disk\n",
    "joblib.dump(model, 'tree.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr id=\"import\">\n",
    "\n",
    "<h2>8. Classification Overview</h2>\n",
    "\n",
    "\n",
    "#### Classification  \n",
    "Classification is a statistical and machine learning technique used to assign labels or categories to data points based on one or more features (independent variables).  \n",
    "The goal of classification is to determine the category or class of a data point by learning from labeled training data. This makes classification a cornerstone of predictive modeling, widely used in tasks like spam detection, medical diagnosis, and image recognition.  \n",
    "\n",
    "#### Goodness of Classification  \n",
    "Goodness of classification refers to how well the model assigns the correct class labels to new, unseen data. A good classification model balances capturing patterns in the data without overfitting to noise.\n",
    "\n",
    "---\n",
    "\n",
    "#### Logistic Regression  \n",
    "Logistic regression is a classification algorithm used to predict a binary outcome (e.g., 0 or 1, True or False, Yes or No) based on one or more independent variables. Despite its name, logistic regression is not used for regression tasks but for classification.\n",
    "\n",
    "The logistic regression model predicts the probability that an observation belongs to a particular class. The relationship between the independent variables and the predicted probability is modeled using the **logistic (sigmoid) function**:\n",
    "\n",
    "$$\n",
    "P(y=1|X) = \\frac{1}{1 + e^{-(a_0 + a_1x_1 + a_2x_2 + \\dots)}}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "\n",
    "- \\( P(y=1|X) \\): The predicted probability of the positive class (class 1).  \n",
    "\n",
    "- \\( a_0 \\): The intercept (bias).  \n",
    "\n",
    "- \\( a_1, a_2, ...\\): The coefficients of the independent variables.  \n",
    "\n",
    "The model output is a probability value between 0 and 1, which is thresholded (e.g., at 0.5) to decide the predicted class. Logistic regression works well for binary classification problems and is interpretable and computationally efficient.\n",
    "\n",
    "---\n",
    "\n",
    "#### How Logistic Regression Relates to Linear Regression  \n",
    "Logistic regression is closely related to linear regression, as it starts with the same linear equation to model the relationship between independent variables and the target variable:\n",
    "\n",
    "$$\n",
    "z = a_0 + a_1x_1 + a_2x_2 + \\dots\n",
    "$$\n",
    "\n",
    "In linear regression, this equation directly predicts the dependent variable \\( y \\). However, in logistic regression, this linear combination \\( z \\) is transformed using the logistic (sigmoid) function:\n",
    "\n",
    "$$\n",
    "P(y=1|X) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "This transformation ensures that the output is always between 0 and 1, making it suitable for probability estimation. Logistic regression is called \"regression\" because it models the underlying relationship between the independent variables and the log-odds of the outcome:\n",
    "\n",
    "$$\n",
    "\\text{log-odds} = \\ln\\left(\\frac{P(y=1|X)}{1 - P(y=1|X)}\\right) = z\n",
    "$$\n",
    "\n",
    "The log-odds (logarithm of the odds ratio) is a linear function of the independent variables, similar to linear regression.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why is Logistic Regression Called Regression Despite Being a Classification Algorithm?  \n",
    "Logistic regression retains the \"regression\" name because:  \n",
    "1. It uses a linear regression-like equation as its foundation.  \n",
    "2. It estimates parameters (coefficients) using a regression-like approach (maximum likelihood estimation).  \n",
    "3. It predicts a continuous value (probability) before applying a threshold for classification.  \n",
    "\n",
    "Thus, logistic regression combines the interpretability and simplicity of linear regression with the ability to handle classification problems, making it a versatile and widely used algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary feature for low-emission\n",
    "df['low-emission'] = df['CO2 Emissions [g/km]'] <= 200\n",
    "\n",
    "df['low-emission'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# get input and output variables\n",
    "x = df[['Engine Size [L]', 'Fuel Consumption Comb [L/100 km]', 'Fuel Type']]\n",
    "y = df['low-emission']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print('Training set: ', x_train.shape, y_train.shape)\n",
    "print('Testing set: ', x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# print the coefficients and intercept\n",
    "print('Coefficients: ', log_reg.coef_)\n",
    "print('Intercept: ', log_reg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_train = log_reg.predict(x_train)\n",
    "y_pred_test = log_reg.predict(x_test)\n",
    "print('Predictions: ', y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on training and testing sets\n",
    "print('Training set:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print()\n",
    "print('Testing set:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred_test)))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plotly to create an interactive 3D plot\n",
    "\n",
    "# create a column for true positive and false positive and true negative and false negative\n",
    "df['y_pred'] = log_reg.predict(x)\n",
    "df['result'] = ''\n",
    "df['result'][(df['low-emission'] == True) & (df['y_pred'] == True)] = 'TP'\n",
    "df['result'][(df['low-emission'] == False) & (df['y_pred'] == False)] = 'TN'\n",
    "df['result'][(df['low-emission'] == True) & (df['y_pred'] == False)] = 'FN'\n",
    "df['result'][(df['low-emission'] == False) & (df['y_pred'] == True)] = 'FP'\n",
    "\n",
    "# plot scatter plot in 3D\n",
    "fig = px.scatter_3d(df, x='Engine Size [L]', y='Fuel Consumption Comb [L/100 km]', z='Fuel Type', color='result')\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "\n",
    "# get the coefficients and intercept\n",
    "coefficients = log_reg.coef_[0]\n",
    "intercept = log_reg.intercept_[0]\n",
    "\n",
    "# plot the decision boundary\n",
    "# x3 = -(b + w1*x1 + w2*x2) / w3\n",
    "x1 = np.arange(0.0, 10.0, 0.1)\n",
    "x2 = np.arange(0.0, 30.0, 0.1)\n",
    "x1, x2 = np.meshgrid(x1, x2)\n",
    "x3 = -(intercept + coefficients[0]*x1 + coefficients[1]*x2) / coefficients[2]\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x1,\n",
    "    y=x2,\n",
    "    z=x3,\n",
    "    opacity=0.2,\n",
    "    showscale=False,    \n",
    "    surfacecolor=x3-x3,\n",
    "))\n",
    "\n",
    "# update figure size\n",
    "fig.update_layout(\n",
    "    height=700,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### NOTE\n",
    "Model development and evaluation is an iterative process.  \n",
    "We typically try multiple models and different combinations of parameters and select the most accurate based on the evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"margin-top: 4rem;\">\n",
    "<h2>Author</h2>\n",
    "\n",
    "<a href=\"https://github.com/SamerHany\">Samer Hany</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>References</h2>\n",
    "<a href=\"https://www.w3schools.com/python/default.asp\">w3schools.com</a>\n",
    "<br>\n",
    "<a href=\"https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/\">geeksforgeeks.com</a>\n",
    "<br>\n",
    "<a href=\"https://www.kaggle.com/datasets/mrmorj/car-fuel-emissions\">CO2 emissions dataset (kaggle.com)</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
